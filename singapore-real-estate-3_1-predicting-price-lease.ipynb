{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal\n",
    "We are going to build a model for predicting a price for apartments and condominiums in Singapore.\n",
    "\n",
    "##### Task for the current workbook:\n",
    "- Build some models for predicting the price, based on the data prepared in the workbook 1 and the insights into the data in the workbook 2\n",
    "\n",
    "#### Strategy\n",
    "- Based on the analysis in the Workbook 2, we concluded that linear models are not suitable for this dataset because of significant non-linearities in the data.\n",
    "- Therefore, we will be using models which are more suitable for non-linear data, such as Decision Tree regression, Random forest regression, and artificial neural networks.\n",
    "- Using some variables such as project_name, street and postal_code will lead to high-dimensional binary vector spaces. We can use two strategies to deal with this:\n",
    "    - Try models without these variables. Latitude and longitude may partly [replace them]\n",
    "    - Use dimensionality reduction, e.g. PCA, and run the regressions on that data\n",
    "- Our data includes several years of observations. From the analysis we have seen that the prices have changed over the years. Therefore, we may test how robust the model is by choosing y1 as a train set and y2 as a test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plan:\n",
    "- Use data cleaned from outliers\n",
    "- Numeric and geographical data only:\n",
    "    - Decision tree regression\n",
    "    - Random forest regression\n",
    "- All data:\n",
    "    - PCA:\n",
    "        - Generate principal components. Try different number of PC, make sure that explained_variance_ratio_ cummulative is sufficient (?)\n",
    "        - Decision tree regression\n",
    "        - Random forest regression\n",
    "    - ANN:\n",
    "        - Run ANN on all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_path = \"data/\"\n",
    "file_leases_no_outliers = \"2_lease_no_outliers.csv\" \n",
    "# file_freehold_no_outliers = \"2_freehold_no_outliers.csv\" \n",
    "TRAIN_SIZE = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path+file_leases_no_outliers, parse_dates=['sale_date', 'tenure_start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 68190 entries, 0 to 68189\n",
      "Data columns (total 24 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   project_name        68190 non-null  object        \n",
      " 1   street              68190 non-null  object        \n",
      " 2   postal_district     68190 non-null  int64         \n",
      " 3   sale_type           68190 non-null  object        \n",
      " 4   area_type           68190 non-null  object        \n",
      " 5   property_type       68190 non-null  object        \n",
      " 6   tenure_type         68190 non-null  object        \n",
      " 7   mkt_segment         68190 non-null  object        \n",
      " 8   sale_month          68190 non-null  int64         \n",
      " 9   sale_year           68190 non-null  int64         \n",
      " 10  sale_date           68190 non-null  datetime64[ns]\n",
      " 11  tenure_start        68190 non-null  datetime64[ns]\n",
      " 12  tenure_start_y_ago  68190 non-null  float64       \n",
      " 13  tenure_years        68190 non-null  float64       \n",
      " 14  tenure_remained     68190 non-null  float64       \n",
      " 15  floor_level         68190 non-null  float64       \n",
      " 16  max_floor           68190 non-null  float64       \n",
      " 17  area_sqft           68190 non-null  float64       \n",
      " 18  lat                 68190 non-null  float64       \n",
      " 19  price_total         68190 non-null  float64       \n",
      " 20  lon                 68190 non-null  float64       \n",
      " 21  lat_adj             68190 non-null  float64       \n",
      " 22  lon_adj             68190 non-null  float64       \n",
      " 23  price_sqft          68190 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(12), int64(3), object(7)\n",
      "memory usage: 12.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Lease'], dtype=object)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tenure_type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regression on variables excluding project_name and street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['project_name', 'street', 'sale_date', 'tenure_start', \n",
    "                             'tenure_years', 'lat', 'lon', 'price_total' ])\n",
    "dataset_1 = df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 68190 entries, 0 to 68189\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   postal_district     68190 non-null  int64  \n",
      " 1   sale_type           68190 non-null  object \n",
      " 2   area_type           68190 non-null  object \n",
      " 3   property_type       68190 non-null  object \n",
      " 4   tenure_type         68190 non-null  object \n",
      " 5   mkt_segment         68190 non-null  object \n",
      " 6   sale_month          68190 non-null  int64  \n",
      " 7   sale_year           68190 non-null  int64  \n",
      " 8   tenure_start_y_ago  68190 non-null  float64\n",
      " 9   tenure_remained     68190 non-null  float64\n",
      " 10  floor_level         68190 non-null  float64\n",
      " 11  max_floor           68190 non-null  float64\n",
      " 12  area_sqft           68190 non-null  float64\n",
      " 13  lat_adj             68190 non-null  float64\n",
      " 14  lon_adj             68190 non-null  float64\n",
      " 15  price_sqft          68190 non-null  float64\n",
      "dtypes: float64(8), int64(3), object(5)\n",
      "memory usage: 8.3+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = dataset_1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_1[:, :-1]\n",
    "y = dataset_1[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0, 1, 2, 3 , 4, 5, 6, 7])], \n",
    "                       remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ct.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entire dataset approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = TRAIN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:, -7:] = sc.fit_transform(X_train[:, -7:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[:, -7:] = sc.transform(X_test[:, -7:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save backup\n",
    "X_train_copy = X_train.copy()\n",
    "X_test_copy = X_test.copy()\n",
    "y_train_copy = y_train.copy()\n",
    "y_test_copy = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_1 = DecisionTreeRegressor()\n",
    "tree_1.fit(X_train, y_train)\n",
    "y_pred_tree_1 = tree_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9674631023066488"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_tree_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_1 = RandomForestRegressor()\n",
    "forest_1.fit(X_train, y_train)\n",
    "y_pred_forest_1 = forest_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9801877764273224"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_forest_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-split approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 68190 entries, 0 to 68189\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   postal_district     68190 non-null  int64  \n",
      " 1   sale_type           68190 non-null  object \n",
      " 2   area_type           68190 non-null  object \n",
      " 3   property_type       68190 non-null  object \n",
      " 4   tenure_type         68190 non-null  object \n",
      " 5   mkt_segment         68190 non-null  object \n",
      " 6   sale_month          68190 non-null  int64  \n",
      " 7   sale_year           68190 non-null  int64  \n",
      " 8   tenure_start_y_ago  68190 non-null  float64\n",
      " 9   tenure_remained     68190 non-null  float64\n",
      " 10  floor_level         68190 non-null  float64\n",
      " 11  max_floor           68190 non-null  float64\n",
      " 12  area_sqft           68190 non-null  float64\n",
      " 13  lat_adj             68190 non-null  float64\n",
      " 14  lon_adj             68190 non-null  float64\n",
      " 15  price_sqft          68190 non-null  float64\n",
      "dtypes: float64(8), int64(3), object(5)\n",
      "memory usage: 8.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2_train = df_clean[df_clean.sale_year == 2022].drop(columns=['sale_year']).values\n",
    "dataset_2_test = df_clean[df_clean.sale_year == 2023].drop(columns=['sale_year']).values\n",
    "X_train_2 = dataset_2_train[:, :-1]\n",
    "y_train_2 = dataset_2_train[:, -1]\n",
    "X_test_2 = dataset_2_test[:, :-1]\n",
    "y_test_2 = dataset_2_test[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature scaling and column transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one column less, as sale_year column is removed\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0, 1, 2, 3 , 4, 5, 6])], \n",
    "                       remainder='passthrough')\n",
    "X_train_2 = ct.fit_transform(X_train_2).toarray()\n",
    "X_test_2 = ct.transform(X_test_2).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_2 = StandardScaler()\n",
    "X_train_2[:, -7:] = sc_2.fit_transform(X_train_2[:, -7:])\n",
    "X_test_2[:, -7:] = sc_2.transform(X_test_2[:, -7:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_2 = DecisionTreeRegressor()\n",
    "tree_2.fit(X_train_2, y_train_2)\n",
    "y_pred_2 = tree_2.predict(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8479303410196957"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test_2, y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_2 = RandomForestRegressor()\n",
    "forest_2.fit(X_train_2, y_train_2)\n",
    "y_pred_forest_2 = forest_2.predict(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8195603327663269"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test_2, y_pred_forest_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "- As expected, using year_1 data for training and year_2 data for testing is less efficient, because we are effectively loosing the information about the year. \n",
    "- However, the predictions are still quite high, meaning that overall the model is robust and we can use the entire dataset model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 68190 entries, 0 to 68189\n",
      "Data columns (total 24 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   project_name        68190 non-null  object        \n",
      " 1   street              68190 non-null  object        \n",
      " 2   postal_district     68190 non-null  int64         \n",
      " 3   sale_type           68190 non-null  object        \n",
      " 4   area_type           68190 non-null  object        \n",
      " 5   property_type       68190 non-null  object        \n",
      " 6   tenure_type         68190 non-null  object        \n",
      " 7   mkt_segment         68190 non-null  object        \n",
      " 8   sale_month          68190 non-null  int64         \n",
      " 9   sale_year           68190 non-null  int64         \n",
      " 10  sale_date           68190 non-null  datetime64[ns]\n",
      " 11  tenure_start        68190 non-null  datetime64[ns]\n",
      " 12  tenure_start_y_ago  68190 non-null  float64       \n",
      " 13  tenure_years        68190 non-null  float64       \n",
      " 14  tenure_remained     68190 non-null  float64       \n",
      " 15  floor_level         68190 non-null  float64       \n",
      " 16  max_floor           68190 non-null  float64       \n",
      " 17  area_sqft           68190 non-null  float64       \n",
      " 18  lat                 68190 non-null  float64       \n",
      " 19  price_total         68190 non-null  float64       \n",
      " 20  lon                 68190 non-null  float64       \n",
      " 21  lat_adj             68190 non-null  float64       \n",
      " 22  lon_adj             68190 non-null  float64       \n",
      " 23  price_sqft          68190 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(12), int64(3), object(7)\n",
      "memory usage: 12.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = df.drop(columns=['sale_date', 'tenure_start', 'tenure_years', 'lat', 'lon', 'price_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 68190 entries, 0 to 68189\n",
      "Data columns (total 18 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   project_name        68190 non-null  object \n",
      " 1   street              68190 non-null  object \n",
      " 2   postal_district     68190 non-null  int64  \n",
      " 3   sale_type           68190 non-null  object \n",
      " 4   area_type           68190 non-null  object \n",
      " 5   property_type       68190 non-null  object \n",
      " 6   tenure_type         68190 non-null  object \n",
      " 7   mkt_segment         68190 non-null  object \n",
      " 8   sale_month          68190 non-null  int64  \n",
      " 9   sale_year           68190 non-null  int64  \n",
      " 10  tenure_start_y_ago  68190 non-null  float64\n",
      " 11  tenure_remained     68190 non-null  float64\n",
      " 12  floor_level         68190 non-null  float64\n",
      " 13  max_floor           68190 non-null  float64\n",
      " 14  area_sqft           68190 non-null  float64\n",
      " 15  lat_adj             68190 non-null  float64\n",
      " 16  lon_adj             68190 non-null  float64\n",
      " 17  price_sqft          68190 non-null  float64\n",
      "dtypes: float64(8), int64(3), object(7)\n",
      "memory usage: 9.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_pca.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pca = df_pca.values\n",
    "X_pca = dataset_pca[:, :-1]\n",
    "y_pca = dataset_pca[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_transform = [0, 1, 2, 3 , 4, 5, 6, 7, 8, 9]\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), columns_to_transform)], \n",
    "                       remainder='passthrough')\n",
    "X_pca_ct = ct.fit_transform(X_pca).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca_ct, y_pca, train_size=TRAIN_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "sc_pca = StandardScaler()\n",
    "X_train_pca[:, -7:] = sc_pca.fit_transform(X_train_pca[:, -7:])\n",
    "\n",
    "#test\n",
    "X_test_pca[:, -7:] = sc_pca.transform(X_test_pca[:, -7:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "pca = PCA(n_components=56)\n",
    "X_train_pca_transformed = pca.fit_transform(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21717893, 0.37852043, 0.45077998, 0.51573153, 0.57036805,\n",
       "       0.60203081, 0.62764488, 0.64917147, 0.66856273, 0.68470654,\n",
       "       0.69858351, 0.71069495, 0.72221395, 0.73198157, 0.74075578,\n",
       "       0.74879195, 0.75646271, 0.76398011, 0.77104541, 0.7779921 ,\n",
       "       0.78474553, 0.79128798, 0.79731208, 0.80316537, 0.8089406 ,\n",
       "       0.81437913, 0.81968236, 0.82487921, 0.82986669, 0.83440376,\n",
       "       0.83877598, 0.84280312, 0.84647744, 0.84997124, 0.85331465,\n",
       "       0.85643278, 0.85939695, 0.86231037, 0.86505741, 0.8677039 ,\n",
       "       0.87024725, 0.87272106, 0.87511667, 0.87748959, 0.87983045,\n",
       "       0.88209423, 0.8843042 , 0.88640765, 0.88841833, 0.89035094,\n",
       "       0.89224001, 0.89401998, 0.89576708, 0.89743615, 0.89904122,\n",
       "       0.90059194])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#increasing the number of components until explained variance is 90%\n",
    "pca.explained_variance_ratio_.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "X_test_pca_transformed = pca.transform(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression models on PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pca = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pca.fit(X_train_pca_transformed, y_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr_pca = lr_pca.predict(X_test_pca_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.883844990666613"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test_pca, y_pred_lr_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment:\n",
    "- Although the original data contained significant non-linearity, Linear model can be used with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9200034909574065"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_pca = DecisionTreeRegressor()\n",
    "tree_pca.fit(X_train_pca_transformed, y_train_pca)\n",
    "y_pred_tree_pca = tree_pca.predict(X_test_pca_transformed)\n",
    "r2_score(y_test_pca, y_pred_tree_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9630431761807127"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_pca = RandomForestRegressor()\n",
    "forest_pca.fit(X_train_pca_transformed, y_train_pca)\n",
    "y_pred_forest_pca = forest_pca.predict(X_test_pca_transformed)\n",
    "r2_score(y_test_pca, y_pred_forest_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ann = df.drop(columns=['sale_date', 'tenure_start', 'tenure_years', 'lat', 'lon', 'price_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 68190 entries, 0 to 68189\n",
      "Data columns (total 18 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   project_name        68190 non-null  object \n",
      " 1   street              68190 non-null  object \n",
      " 2   postal_district     68190 non-null  int64  \n",
      " 3   sale_type           68190 non-null  object \n",
      " 4   area_type           68190 non-null  object \n",
      " 5   property_type       68190 non-null  object \n",
      " 6   tenure_type         68190 non-null  object \n",
      " 7   mkt_segment         68190 non-null  object \n",
      " 8   sale_month          68190 non-null  int64  \n",
      " 9   sale_year           68190 non-null  int64  \n",
      " 10  tenure_start_y_ago  68190 non-null  float64\n",
      " 11  tenure_remained     68190 non-null  float64\n",
      " 12  floor_level         68190 non-null  float64\n",
      " 13  max_floor           68190 non-null  float64\n",
      " 14  area_sqft           68190 non-null  float64\n",
      " 15  lat_adj             68190 non-null  float64\n",
      " 16  lon_adj             68190 non-null  float64\n",
      " 17  price_sqft          68190 non-null  float64\n",
      "dtypes: float64(8), int64(3), object(7)\n",
      "memory usage: 9.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ann.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ann = df_ann.values\n",
    "X_ann = dataset_ann[:, :-1]\n",
    "y_ann = dataset_ann[:, -1].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ann.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoding categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_transform = [0, 1, 2, 3 , 4, 5, 6, 7, 8, 9]\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), columns_to_transform)], \n",
    "                       remainder='passthrough')\n",
    "X_ann = ct.fit_transform(X_ann).toarray().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ann, X_test_ann, y_train_ann, y_test_ann = train_test_split(X_ann, y_ann, train_size=TRAIN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_ann = StandardScaler()\n",
    "X_train_ann = sc_ann.fit_transform(X_train_ann)\n",
    "X_test_ann = sc_ann.transform(X_test_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_ann.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding layers\n",
    "ann.add(tf.keras.layers.Input(shape=(X_train_ann.shape[1])))\n",
    "ann.add(tf.keras.layers.Dense(512, activation='relu'))  \n",
    "ann.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = [MeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1492/1492 [==============================] - 7s 4ms/step - loss: 85973.3828 - mean_squared_error: 85973.3828\n",
      "Epoch 2/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 13794.3896 - mean_squared_error: 13794.3896\n",
      "Epoch 3/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 12858.9229 - mean_squared_error: 12858.9229\n",
      "Epoch 4/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 11985.8135 - mean_squared_error: 11985.8135\n",
      "Epoch 5/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 11283.1523 - mean_squared_error: 11283.1523\n",
      "Epoch 6/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 10904.3584 - mean_squared_error: 10904.3584\n",
      "Epoch 7/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 10209.6133 - mean_squared_error: 10209.6133\n",
      "Epoch 8/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 9757.9785 - mean_squared_error: 9757.9785\n",
      "Epoch 9/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 9603.1016 - mean_squared_error: 9603.1016\n",
      "Epoch 10/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 9353.2021 - mean_squared_error: 9353.2021\n",
      "Epoch 11/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 9057.1836 - mean_squared_error: 9057.1836\n",
      "Epoch 12/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 8774.4824 - mean_squared_error: 8774.4824\n",
      "Epoch 13/100\n",
      "1492/1492 [==============================] - 7s 4ms/step - loss: 8491.6953 - mean_squared_error: 8491.6953\n",
      "Epoch 14/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 8302.3311 - mean_squared_error: 8302.3311\n",
      "Epoch 15/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 8247.3242 - mean_squared_error: 8247.3242\n",
      "Epoch 16/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 7871.2671 - mean_squared_error: 7871.2671\n",
      "Epoch 17/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 7742.1953 - mean_squared_error: 7742.1953\n",
      "Epoch 18/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 7479.6021 - mean_squared_error: 7479.6021\n",
      "Epoch 19/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 7454.0527 - mean_squared_error: 7454.0527\n",
      "Epoch 20/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 7213.6016 - mean_squared_error: 7213.6016\n",
      "Epoch 21/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 7058.4292 - mean_squared_error: 7058.4292\n",
      "Epoch 22/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 7038.2041 - mean_squared_error: 7038.2041\n",
      "Epoch 23/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 6821.2231 - mean_squared_error: 6821.2231\n",
      "Epoch 24/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 6680.5083 - mean_squared_error: 6680.5083\n",
      "Epoch 25/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 6516.1152 - mean_squared_error: 6516.1152\n",
      "Epoch 26/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 6428.6499 - mean_squared_error: 6428.6499\n",
      "Epoch 27/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 6321.4185 - mean_squared_error: 6321.4185\n",
      "Epoch 28/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 6205.7427 - mean_squared_error: 6205.7427\n",
      "Epoch 29/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 6119.0903 - mean_squared_error: 6119.0903\n",
      "Epoch 30/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 6018.8438 - mean_squared_error: 6018.8438\n",
      "Epoch 31/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 6003.9951 - mean_squared_error: 6003.9951: 0s - loss: 6014.3818 - mean_squared_error:\n",
      "Epoch 32/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 5801.2729 - mean_squared_error: 5801.2729\n",
      "Epoch 33/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 5866.5889 - mean_squared_error: 5866.5889\n",
      "Epoch 34/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 5726.9790 - mean_squared_error: 5726.9790\n",
      "Epoch 35/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 5663.0137 - mean_squared_error: 5663.0137\n",
      "Epoch 36/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 5538.0669 - mean_squared_error: 5538.0669\n",
      "Epoch 37/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 5540.0483 - mean_squared_error: 5540.0483\n",
      "Epoch 38/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 5413.0732 - mean_squared_error: 5413.0732\n",
      "Epoch 39/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 5309.5952 - mean_squared_error: 5309.5952\n",
      "Epoch 40/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 5341.0537 - mean_squared_error: 5341.0537\n",
      "Epoch 41/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 5257.7793 - mean_squared_error: 5257.7793\n",
      "Epoch 42/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 5149.0020 - mean_squared_error: 5149.0020\n",
      "Epoch 43/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 5163.2461 - mean_squared_error: 5163.2461\n",
      "Epoch 44/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 5085.7700 - mean_squared_error: 5085.7700\n",
      "Epoch 45/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 4996.1221 - mean_squared_error: 4996.1221\n",
      "Epoch 46/100\n",
      "1492/1492 [==============================] - 7s 5ms/step - loss: 5013.1997 - mean_squared_error: 5013.1997\n",
      "Epoch 47/100\n",
      "1492/1492 [==============================] - 7s 5ms/step - loss: 4906.9648 - mean_squared_error: 4906.9648\n",
      "Epoch 48/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 4911.9380 - mean_squared_error: 4911.9380\n",
      "Epoch 49/100\n",
      "1492/1492 [==============================] - 7s 4ms/step - loss: 4853.1021 - mean_squared_error: 4853.1021\n",
      "Epoch 50/100\n",
      "1492/1492 [==============================] - 9s 6ms/step - loss: 4751.4624 - mean_squared_error: 4751.4624\n",
      "Epoch 51/100\n",
      "1492/1492 [==============================] - 7s 5ms/step - loss: 4722.5073 - mean_squared_error: 4722.5073\n",
      "Epoch 52/100\n",
      "1492/1492 [==============================] - 8s 6ms/step - loss: 4761.6733 - mean_squared_error: 4761.6733\n",
      "Epoch 53/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 4614.2993 - mean_squared_error: 4614.2993\n",
      "Epoch 54/100\n",
      "1492/1492 [==============================] - 7s 4ms/step - loss: 4618.9390 - mean_squared_error: 4618.9390\n",
      "Epoch 55/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 4587.9878 - mean_squared_error: 4587.9878\n",
      "Epoch 56/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 4560.0840 - mean_squared_error: 4560.0840\n",
      "Epoch 57/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 4453.2368 - mean_squared_error: 4453.2368\n",
      "Epoch 58/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 4458.3628 - mean_squared_error: 4458.3628\n",
      "Epoch 59/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 4416.2817 - mean_squared_error: 4416.2817\n",
      "Epoch 60/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 4395.7212 - mean_squared_error: 4395.7212\n",
      "Epoch 61/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 4317.1816 - mean_squared_error: 4317.1816\n",
      "Epoch 62/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 4330.9614 - mean_squared_error: 4330.9614\n",
      "Epoch 63/100\n",
      "1492/1492 [==============================] - 7s 4ms/step - loss: 4260.2358 - mean_squared_error: 4260.2358\n",
      "Epoch 64/100\n",
      "1492/1492 [==============================] - 9s 6ms/step - loss: 4263.5728 - mean_squared_error: 4263.5728\n",
      "Epoch 65/100\n",
      "1492/1492 [==============================] - 9s 6ms/step - loss: 4248.1699 - mean_squared_error: 4248.1699\n",
      "Epoch 66/100\n",
      "1492/1492 [==============================] - 7s 4ms/step - loss: 4189.3652 - mean_squared_error: 4189.3652\n",
      "Epoch 67/100\n",
      "1492/1492 [==============================] - 7s 4ms/step - loss: 4198.9214 - mean_squared_error: 4198.9214\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1492/1492 [==============================] - 7s 4ms/step - loss: 4142.0234 - mean_squared_error: 4142.0234: 0s - loss: 4081.\n",
      "Epoch 69/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 4105.3345 - mean_squared_error: 4105.3345\n",
      "Epoch 70/100\n",
      "1492/1492 [==============================] - 7s 5ms/step - loss: 4105.0981 - mean_squared_error: 4105.0981\n",
      "Epoch 71/100\n",
      "1492/1492 [==============================] - 7s 5ms/step - loss: 4094.9333 - mean_squared_error: 4094.9333\n",
      "Epoch 72/100\n",
      "1492/1492 [==============================] - 9s 6ms/step - loss: 4015.9407 - mean_squared_error: 4015.9407\n",
      "Epoch 73/100\n",
      "1492/1492 [==============================] - 7s 4ms/step - loss: 4047.3352 - mean_squared_error: 4047.3352\n",
      "Epoch 74/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 4011.9946 - mean_squared_error: 4011.9946\n",
      "Epoch 75/100\n",
      "1492/1492 [==============================] - 7s 4ms/step - loss: 4013.8071 - mean_squared_error: 4013.8071\n",
      "Epoch 76/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 3891.3818 - mean_squared_error: 3891.3818: 0s - loss: 3895.8455 - mea\n",
      "Epoch 77/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 3932.2646 - mean_squared_error: 3932.2646\n",
      "Epoch 78/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 3937.8794 - mean_squared_error: 3937.8794\n",
      "Epoch 79/100\n",
      "1492/1492 [==============================] - 7s 4ms/step - loss: 3900.7158 - mean_squared_error: 3900.7158: 1s - los\n",
      "Epoch 80/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 3829.6719 - mean_squared_error: 3829.6719\n",
      "Epoch 81/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 3866.3533 - mean_squared_error: 3866.3533\n",
      "Epoch 82/100\n",
      "1492/1492 [==============================] - 7s 4ms/step - loss: 3800.0596 - mean_squared_error: 3800.0596\n",
      "Epoch 83/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 3794.3032 - mean_squared_error: 3794.3032\n",
      "Epoch 84/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 3755.5605 - mean_squared_error: 3755.5605\n",
      "Epoch 85/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 3762.9246 - mean_squared_error: 3762.9246\n",
      "Epoch 86/100\n",
      "1492/1492 [==============================] - 7s 5ms/step - loss: 3718.9160 - mean_squared_error: 3718.9160\n",
      "Epoch 87/100\n",
      "1492/1492 [==============================] - 7s 5ms/step - loss: 3681.0010 - mean_squared_error: 3681.0010\n",
      "Epoch 88/100\n",
      "1492/1492 [==============================] - 7s 5ms/step - loss: 3682.9333 - mean_squared_error: 3682.9333\n",
      "Epoch 89/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 3719.2808 - mean_squared_error: 3719.2808\n",
      "Epoch 90/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 3588.3040 - mean_squared_error: 3588.3040\n",
      "Epoch 91/100\n",
      "1492/1492 [==============================] - 7s 4ms/step - loss: 3667.7334 - mean_squared_error: 3667.7334\n",
      "Epoch 92/100\n",
      "1492/1492 [==============================] - 7s 4ms/step - loss: 3605.9612 - mean_squared_error: 3605.9612\n",
      "Epoch 93/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 3651.1904 - mean_squared_error: 3651.1904\n",
      "Epoch 94/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 3547.0725 - mean_squared_error: 3547.0725\n",
      "Epoch 95/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 3529.3359 - mean_squared_error: 3529.3359\n",
      "Epoch 96/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 3557.6897 - mean_squared_error: 3557.6897\n",
      "Epoch 97/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 3477.6694 - mean_squared_error: 3477.6694\n",
      "Epoch 98/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 3504.3430 - mean_squared_error: 3504.3430\n",
      "Epoch 99/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 3487.2827 - mean_squared_error: 3487.2827\n",
      "Epoch 100/100\n",
      "1492/1492 [==============================] - 6s 4ms/step - loss: 3459.9673 - mean_squared_error: 3459.9673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16d403a90>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training\n",
    "ann.fit(X_train_ann, y_train_ann, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ann = ann.predict(X_test_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9735127021005343"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test_ann, y_pred_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
